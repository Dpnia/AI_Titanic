{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embarked has next classes:  ['S' 'C' 'Q' nan]\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\kjh43\\AppData\\Local\\Temp\\tmped8si5d9\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_num_ps_replicas': 0, 'tf_random_seed': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000023EB7926860>, '_environment': 'local', '_task_type': None, '_evaluation_master': '', 'keep_checkpoint_max': 5, 'save_summary_steps': 100, 'keep_checkpoint_every_n_hours': 10000, 'tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", 'save_checkpoints_steps': None, '_task_id': 0, '_is_chief': True, 'save_checkpoints_secs': 600, '_master': ''}\n",
      "WARNING:tensorflow:From <ipython-input-4-e73711a447cd>:39 in <module>.: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-4-e73711a447cd>:39 in <module>.: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-4-e73711a447cd>:32 in categorical_model.: categorical_variable (from tensorflow.contrib.learn.python.learn.ops.embeddings_ops) is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Use `tf.contrib.layers.embed_sequence` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\kjh43\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\ops\\embeddings_ops.py:88 in categorical_variable.: embedding_lookup (from tensorflow.contrib.learn.python.learn.ops.embeddings_ops) is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Use `tf.embedding_lookup` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\kjh43\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\models.py:175 in logistic_regression.: softmax_classifier (from tensorflow.contrib.learn.python.learn.ops.losses_ops) is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Use `tf.contrib.losses.softmax_cross_entropy` and explicit logits computation.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:loss = 0.687726, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\kjh43\\AppData\\Local\\Temp\\tmped8si5d9\\model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:loss = 0.655542, step = 101\n",
      "INFO:tensorflow:global_step/sec: 34.8628\n",
      "INFO:tensorflow:loss = 0.650375, step = 201\n",
      "INFO:tensorflow:global_step/sec: 43.23\n",
      "INFO:tensorflow:loss = 0.649572, step = 301\n",
      "INFO:tensorflow:global_step/sec: 45.1972\n",
      "INFO:tensorflow:loss = 0.649408, step = 401\n",
      "INFO:tensorflow:global_step/sec: 42.8323\n",
      "INFO:tensorflow:loss = 0.649331, step = 501\n",
      "INFO:tensorflow:global_step/sec: 40.2789\n",
      "INFO:tensorflow:loss = 0.649268, step = 601\n",
      "INFO:tensorflow:global_step/sec: 43.2387\n",
      "INFO:tensorflow:loss = 0.649209, step = 701\n",
      "INFO:tensorflow:global_step/sec: 45.6021\n",
      "INFO:tensorflow:loss = 0.649152, step = 801\n",
      "INFO:tensorflow:global_step/sec: 45.5214\n",
      "INFO:tensorflow:loss = 0.649097, step = 901\n",
      "INFO:tensorflow:global_step/sec: 45.4575\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\kjh43\\AppData\\Local\\Temp\\tmped8si5d9\\model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:Loss for final step: 0.649045.\n",
      "WARNING:tensorflow:From <ipython-input-4-e73711a447cd>:41 in <module>.: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-4-e73711a447cd>:32 in categorical_model.: categorical_variable (from tensorflow.contrib.learn.python.learn.ops.embeddings_ops) is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Use `tf.contrib.layers.embed_sequence` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\kjh43\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\ops\\embeddings_ops.py:88 in categorical_variable.: embedding_lookup (from tensorflow.contrib.learn.python.learn.ops.embeddings_ops) is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Use `tf.embedding_lookup` instead.\n",
      "WARNING:tensorflow:From C:\\Users\\kjh43\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\models.py:175 in logistic_regression.: softmax_classifier (from tensorflow.contrib.learn.python.learn.ops.losses_ops) is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Use `tf.contrib.losses.softmax_cross_entropy` and explicit logits computation.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected sequence or array-like, got <class 'generator'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e73711a447cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy: {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ROC: {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\kjh43\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mdiffering_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_nonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\kjh43\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\kjh43\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \"\"\"\n\u001b[1;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         raise ValueError(\"Found arrays with inconsistent numbers of samples: \"\n",
      "\u001b[0;32mC:\\Users\\kjh43\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \"\"\"\n\u001b[1;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         raise ValueError(\"Found arrays with inconsistent numbers of samples: \"\n",
      "\u001b[0;32mC:\\Users\\kjh43\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             raise TypeError(\"Expected sequence or array-like, got %s\" %\n\u001b[0;32m--> 118\u001b[0;31m                             type(x))\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected sequence or array-like, got <class 'generator'>"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn import metrics, cross_validation\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import layers\n",
    "from tensorflow.contrib import learn\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "data = pandas.read_csv('train.csv')\n",
    "X = data[[\"Embarked\"]]\n",
    "y = data[\"Survived\"]\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "embarked_classes = X_train[\"Embarked\"].unique()\n",
    "n_classes = len(embarked_classes) + 1\n",
    "print('Embarked has next classes: ', embarked_classes)\n",
    "\n",
    "cat_processor = learn.preprocessing.CategoricalProcessor()\n",
    "X_train = np.array(list(cat_processor.fit_transform(X_train)))\n",
    "X_test = np.array(list(cat_processor.transform(X_test)))\n",
    "\n",
    "### Embeddings\n",
    "\n",
    "EMBEDDING_SIZE = 3\n",
    "\n",
    "def categorical_model(features, target):\n",
    "    target = tf.one_hot(target, 2, 1.0, 0.0)\n",
    "    features = learn.ops.categorical_variable(\n",
    "        features, n_classes, embedding_size=EMBEDDING_SIZE, name='embarked')\n",
    "    prediction, loss = learn.models.logistic_regression(tf.squeeze(features, [1]), target)\n",
    "    train_op = layers.optimize_loss(loss,\n",
    "        tf.contrib.framework.get_global_step(), optimizer='SGD', learning_rate=0.05)\n",
    "    return tf.argmax(prediction, dimension=1), loss, train_op\n",
    "\n",
    "classifier = learn.Estimator(model_fn=categorical_model)\n",
    "classifier.fit(X_train, y_train, steps=1000)\n",
    "\n",
    "print(\"Accuracy: {0}\".format(metrics.accuracy_score(classifier.predict(X_test), y_test)))\n",
    "print(\"ROC: {0}\".format(metrics.roc_auc_score(classifier.predict(X_test), y_test)))\n",
    "\n",
    "### One Hot\n",
    "\n",
    "def one_hot_categorical_model(features, target):\n",
    "    target = tf.one_hot(target, 2, 1.0, 0.0)\n",
    "    features = tf.one_hot(features, n_classes, 1.0, 0.0)\n",
    "    prediction, loss = learn.models.logistic_regression(\n",
    "      tf.squeeze(features, [1]), target)\n",
    "    train_op = layers.optimize_loss(loss,\n",
    "        tf.contrib.framework.get_global_step(), optimizer='SGD',\n",
    "        learning_rate=0.01)\n",
    "    return tf.argmax(prediction, dimension=1), loss, train_op\n",
    "\n",
    "classifier = learn.Estimator(model_fn=one_hot_categorical_model)\n",
    "classifier.fit(X_train, y_train, steps=1000)\n",
    "\n",
    "print(\"Accuracy: {0}\".format(metrics.accuracy_score(classifier.predict(X_test), y_test)))\n",
    "print(\"ROC: {0}\".format(metrics.roc_auc_score(classifier.predict(X_test), y_test)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
